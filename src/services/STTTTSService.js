import axios from 'axios'
import { Platform } from 'react-native'
import { Audio } from 'expo-av'
import * as Speech from 'expo-speech'
// å°è¯•å¯¼å…¥expo-speech-recognitionï¼Œå¦‚æœä¸å¯ç”¨åˆ™é™çº§
let SpeechRecognition = null
try {
  SpeechRecognition = require('expo-speech-recognition')
} catch (error) {
  console.log('expo-speech-recognition not available, will use alternative STT')
}

class STTTTSService {
  constructor() {
    this.currentProvider = 'auto' // auto, openai, expo, azure, web
    this.useSimulation = false

    // OpenAIé…ç½®
    this.openaiConfig = {
      sttEndpoint: 'https://api.openai.com/v1/audio/transcriptions',
      ttsEndpoint: 'https://api.openai.com/v1/audio/speech',
      apiKey: '',
      sttModel: 'whisper-1',
      ttsModel: 'tts-1',
      voice: 'alloy',
    }

    // Azureé…ç½®
    this.azureConfig = {
      subscriptionKey: '',
      region: 'eastus',
      language: 'zh-CN',
      voice: 'zh-CN-XiaoxiaoNeural',
    }

    // Google Cloudé…ç½®
    this.googleConfig = {
      apiKey: '',
      sttLanguage: 'zh-CN',
      ttsLanguage: 'zh-CN',
      sttModel: 'latest_short',
      ttsVoice: 'zh-CN-Standard-A',
    }

    // æœåŠ¡å¯ç”¨æ€§çŠ¶æ€
    this.serviceAvailability = {
      sensevoice: true, // SenseVoice-smallè¯­éŸ³è¯†åˆ«
      'edge-tts': true, // Edge TTSè¯­éŸ³åˆæˆ
      expo: true, // Expoæ”¯æŒTTSï¼ŒSTTéœ€è¦æ£€æµ‹
      expoSTT: !!SpeechRecognition, // Expo STTå¯ç”¨æ€§
      web: Platform.OS === 'web',
      openai: false,
      azure: false,
      google: false,
    }

    console.log('ğŸµ STT/TTSæœåŠ¡åˆå§‹åŒ–å®Œæˆ')
  }

  setConfig(config) {
    // OpenAIé…ç½®
    if (config.openai) {
      this.openaiConfig = { ...this.openaiConfig, ...config.openai }
      // è‡ªåŠ¨æ£€æµ‹APIå¯†é’¥å¹¶å¯ç”¨æœåŠ¡
      const hasValidKey = this.openaiConfig.apiKey
                          && this.openaiConfig.apiKey.length > 0
                          && !this.openaiConfig.apiKey.includes('test-key')
      this.serviceAvailability.openai = hasValidKey

      if (hasValidKey) {
        console.log('âœ… OpenAI APIå¯†é’¥å·²é…ç½®ï¼Œå¯ç”¨Whisperè¯­éŸ³è¯†åˆ«')
      } else {
        console.log('âš ï¸ OpenAI APIå¯†é’¥æœªé…ç½®æˆ–ä¸ºæµ‹è¯•å¯†é’¥')
      }
    }

    // Azureé…ç½®
    if (config.azure) {
      this.azureConfig = { ...this.azureConfig, ...config.azure }
      this.serviceAvailability.azure = !!this.azureConfig.subscriptionKey
    }

    // Google Cloudé…ç½®
    if (config.google) {
      this.googleConfig = { ...this.googleConfig, ...config.google }
      const hasValidKey = this.googleConfig.apiKey
                          && this.googleConfig.apiKey.length > 0
                          && this.googleConfig.apiKey.startsWith('AIza')
      this.serviceAvailability.google = hasValidKey

      if (hasValidKey) {
        console.log('âœ… Google Cloud APIå¯†é’¥å·²é…ç½®ï¼Œå¯ç”¨è¯­éŸ³è¯†åˆ«æœåŠ¡')
      } else {
        console.log('âš ï¸ Google Cloud APIå¯†é’¥æœªé…ç½®æˆ–æ ¼å¼é”™è¯¯')
      }
    }

    // è®¾ç½®æä¾›å•†
    if (config.provider) {
      this.currentProvider = config.provider
    }

    console.log('ğŸ“‹ STT/TTSé…ç½®å·²æ›´æ–°:', {
      provider: this.currentProvider,
      availability: this.serviceAvailability,
      googleConfigured: !!this.googleConfig.apiKey,
      openaiConfigured: !!this.openaiConfig.apiKey,
      azureConfigured: !!this.azureConfig.subscriptionKey,
    })
  }

  // è‡ªåŠ¨é€‰æ‹©æœ€ä½³å¯ç”¨æœåŠ¡
  selectBestProvider(type = 'both') {
    console.log(`ğŸ” é€‰æ‹©${type}æœåŠ¡æä¾›å•†...`)
    console.log('å½“å‰æœåŠ¡å¯ç”¨æ€§:', this.serviceAvailability)

    if (type === 'stt') {
      // STTä¼˜å…ˆçº§: Google > OpenAI > Azure > Expo > Web > æ¨¡æ‹Ÿ (Googleæ”¯æŒWAVæ ¼å¼ï¼Œå‡†ç¡®ç‡æ›´é«˜)
      const sttPriorities = ['google', 'openai', 'azure', 'expo', 'web']
      for (const provider of sttPriorities) {
        console.log(`æ£€æŸ¥ ${provider}: ${this.serviceAvailability[provider]}`)
        if (this.serviceAvailability[provider]) {
          const selectedProvider = provider === 'expoSTT' ? 'expo' : provider
          console.log(`âœ… é€‰æ‹©äº† ${selectedProvider}`)
          return selectedProvider
        }
      }
    } else if (type === 'tts') {
      // TTSä¼˜å…ˆçº§: Expo > Google > OpenAI > Azure > Web > æ¨¡æ‹Ÿ (æš‚æ—¶ç¦ç”¨Edge TTSé¿å…å¾ªç¯ä¾èµ–)
      const ttsPriorities = ['expo', 'google', 'openai', 'azure', 'web']
      for (const provider of ttsPriorities) {
        if (this.serviceAvailability[provider]) {
          return provider
        }
      }
    } else {
      // ç»¼åˆä¼˜å…ˆçº§: SenseVoice&EdgeTTS > Google > OpenAI > Azure > Expo(å¦‚æœæœ‰STT) > Web > æ¨¡æ‹Ÿ
      const priorities = ['sensevoice', 'edge-tts', 'google', 'openai', 'azure', 'expo', 'web']
      for (const provider of priorities) {
        if (this.serviceAvailability[provider]) {
          // å¦‚æœé€‰æ‹©expoï¼Œéœ€è¦ç¡®ä¿è‡³å°‘æœ‰TTSæˆ–STTå¯ç”¨
          if (provider === 'expo') {
            if (this.serviceAvailability.expoSTT || this.serviceAvailability.expo) {
              return provider
            }
          } else {
            return provider
          }
        }
      }
    }

    return 'simulation' // é™çº§åˆ°æ¨¡æ‹Ÿæ¨¡å¼
  }

  async speechToText(audioUri) {
    try {
      if (!this.openaiConfig.apiKey) {
        throw new Error('OpenAI APIå¯†é’¥æœªé…ç½®')
      }

      if (!audioUri) {
        throw new Error('éŸ³é¢‘æ–‡ä»¶è·¯å¾„ä¸ºç©º')
      }

      // æ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡æ‹Ÿå½•éŸ³
      if (audioUri && audioUri.startsWith('mock://')) {
        console.log('ğŸ­ æ£€æµ‹åˆ°æ¨¡æ‹Ÿå½•éŸ³ï¼Œä½¿ç”¨æ¨¡æ‹ŸSTTå“åº”')
        return await this.mockSpeechToText(audioUri)
      }

      const formData = new FormData()
      formData.append('file', {
        uri: audioUri,
        type: 'audio/wav',
        name: 'audio.wav',
      })
      formData.append('model', this.openaiConfig.sttModel)
      formData.append('language', 'zh') // æŒ‡å®šä¸­æ–‡

      const response = await axios.post(this.openaiConfig.sttEndpoint, formData, {
        headers: {
          Authorization: `Bearer ${this.openaiConfig.apiKey}`,
          'Content-Type': 'multipart/form-data',
        },
        timeout: 30000,
      })

      if (response.data && response.data.text) {
        return {
          success: true,
          text: response.data.text,
          language: response.data.language,
        }
      }
      throw new Error('æ— æ•ˆçš„STTå“åº”æ ¼å¼')
    } catch (error) {
      console.error('è¯­éŸ³è½¬æ–‡å­—å¤±è´¥:', error)
      return {
        success: false,
        error: error.response?.data?.error?.message || error.message,
      }
    }
  }

  async textToSpeech(text, options = {}) {
    try {
      if (!this.apiKey) {
        throw new Error('APIå¯†é’¥æœªé…ç½®')
      }

      if (!text || text.trim().length === 0) {
        throw new Error('æ–‡æœ¬å†…å®¹ä¸ºç©º')
      }

      const requestData = {
        model: options.model || this.ttsModel,
        input: text,
        voice: options.voice || this.ttsVoice,
        response_format: options.format || 'mp3',
        speed: options.speed || 1.0,
      }

      const response = await axios.post(this.ttsEndpoint, requestData, {
        headers: {
          Authorization: `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        responseType: 'blob',
        timeout: 30000,
      })

      if (response.data) {
        // å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºbase64
        const reader = new FileReader()
        return new Promise((resolve, reject) => {
          reader.onloadend = () => {
            const base64data = reader.result.split(',')[1]
            resolve({
              success: true,
              audioData: base64data,
              format: requestData.response_format,
            })
          }
          reader.onerror = reject
          reader.readAsDataURL(response.data)
        })
      }
      throw new Error('æ— æ•ˆçš„TTSå“åº”æ ¼å¼')
    } catch (error) {
      console.error('æ–‡å­—è½¬è¯­éŸ³å¤±è´¥:', error)
      return {
        success: false,
        error: error.response?.data?.error?.message || error.message,
      }
    }
  }

  // æœ¬åœ°æ¨¡æ‹ŸSTTï¼ˆç”¨äºå¼€å‘æµ‹è¯•ï¼‰
  async mockSpeechToText(audioUri) {
    return new Promise((resolve) => {
      setTimeout(() => {
        const mockTexts = [
          'ä½ å¥½ï¼Œæˆ‘æƒ³å’Œä½ èŠå¤©',
          'ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ',
          'è¯·å¸®æˆ‘ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±',
          'æˆ‘æ„Ÿè§‰æœ‰ç‚¹æ— èŠ',
          'èƒ½ä¸èƒ½è®²ä¸ªç¬‘è¯ï¼Ÿ',
        ]
        const randomText = mockTexts[Math.floor(Math.random() * mockTexts.length)]

        resolve({
          success: true,
          text: randomText,
          language: 'zh',
          isMock: true,
        })
      }, 1000)
    })
  }

  // æœ¬åœ°æ¨¡æ‹ŸTTSï¼ˆç”¨äºå¼€å‘æµ‹è¯•ï¼‰
  async mockTextToSpeech(text) {
    return new Promise((resolve) => {
      setTimeout(() => {
        // è¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿçš„éŸ³é¢‘æ•°æ®
        const mockAudioBase64 = 'UklGRnoGAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQoGAACBhYqFbF1fdJivrJBhNjVgodDbq2EcBj+a2/LDciUFLIHO8tiJNwgZaLvt559NEAxQp+PwtmMcBjiR1/LMeSwFJHfH8N2QQAoUXrTp66hVFApGn+DyvmgfDD2F0fPEbSAFKXvB6+ONQA0PZ7zz26piHgU8ltLuzXEjCC13yO/eizEIHWq4+eGWT' // è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹base64

        resolve({
          success: true,
          audioData: mockAudioBase64,
          format: 'mp3',
          isMock: true,
        })
      }, 1500)
    })
  }

  // Expo TTS (æœ¬åœ°è¯­éŸ³åˆæˆ)
  async expoTextToSpeech(text) {
    try {
      console.log('ğŸµ ä½¿ç”¨Expo TTSæœåŠ¡')

      const options = {
        language: 'zh-CN',
        pitch: 1.0,
        rate: 0.9,
        voice: Platform.OS === 'ios' ? 'com.apple.ttsbundle.Tingting-compact' : undefined,
      }

      await Speech.speak(text, options)

      return {
        success: true,
        message: 'è¯­éŸ³æ’­æ”¾å®Œæˆ',
        provider: 'expo',
        audioData: null, // Expoç›´æ¥æ’­æ”¾ï¼Œä¸è¿”å›éŸ³é¢‘æ•°æ®
      }
    } catch (error) {
      console.error('Expo TTSå¤±è´¥:', error)
      return {
        success: false,
        error: error.message,
        provider: 'expo',
      }
    }
  }

  // Web Speech API TTS
  async webTextToSpeech(text) {
    try {
      if (Platform.OS !== 'web' || !window.speechSynthesis) {
        throw new Error('Web Speech APIä¸å¯ç”¨')
      }

      console.log('ğŸŒ ä½¿ç”¨Web Speech API TTS')

      return new Promise((resolve, reject) => {
        const utterance = new SpeechSynthesisUtterance(text)
        utterance.lang = 'zh-CN'
        utterance.rate = 0.9
        utterance.pitch = 1.0

        utterance.onend = () => {
          resolve({
            success: true,
            message: 'è¯­éŸ³æ’­æ”¾å®Œæˆ',
            provider: 'web',
            audioData: null,
          })
        }

        utterance.onerror = (event) => {
          reject(new Error(`Web Speech TTSé”™è¯¯: ${event.error}`))
        }

        window.speechSynthesis.speak(utterance)
      })
    } catch (error) {
      console.error('Web Speech TTSå¤±è´¥:', error)
      return {
        success: false,
        error: error.message,
        provider: 'web',
      }
    }
  }

  // Expoè¯­éŸ³è¯†åˆ«
  async expoSpeechToText(audioUri) {
    try {
      if (!SpeechRecognition) {
        throw new Error('Expo Speech Recognitionä¸å¯ç”¨')
      }

      console.log('ğŸ“± ä½¿ç”¨Expoè¯­éŸ³è¯†åˆ«')

      // è®¾ç½®è¯†åˆ«é€‰é¡¹
      const options = {
        language: 'zh-CN',
        interimResults: false,
        maxAlternatives: 1,
        continuous: false,
      }

      const result = await SpeechRecognition.requestPermissionsAsync()
      if (result.status !== 'granted') {
        throw new Error('è¯­éŸ³è¯†åˆ«æƒé™è¢«æ‹’ç»')
      }

      // å¼€å§‹è¯†åˆ«
      const recognition = await SpeechRecognition.startAsync(options)

      if (recognition.results && recognition.results.length > 0) {
        const { transcript } = recognition.results[0]
        return {
          success: true,
          text: transcript,
          provider: 'expo',
          confidence: recognition.results[0].confidence || 0.9,
        }
      }

      throw new Error('æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹')
    } catch (error) {
      // ä½¿ç”¨console.logä»¥é¿å…è§¦å‘ä»»ä½•å¯èƒ½çš„é”™è¯¯å¼¹çª—
      console.log('ğŸ¯ Expoè¯­éŸ³è¯†åˆ«å¤±è´¥ï¼ˆå·²æ‹¦æˆªï¼‰:', error.message || error)
      return {
        success: false,
        error: error.message,
        provider: 'expo',
      }
    }
  }

  // æ”¹è¿›ç‰ˆçš„éŸ³é¢‘è½¬æ–‡å­—ï¼ˆä½¿ç”¨çœŸå®å½•éŸ³åˆ†æï¼‰
  async simpleExpoSTT(audioUri) {
    try {
      console.log('ğŸ“± ä½¿ç”¨æ”¹è¿›ç‰ˆExpo STT (åˆ†æçœŸå®å½•éŸ³)')

      if (!audioUri) {
        throw new Error('æ²¡æœ‰å½•éŸ³æ–‡ä»¶')
      }

      // åˆ†æå½•éŸ³æ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯
      let audioInfo = null
      try {
        // å°è¯•è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
        const { Audio } = require('expo-av')
        const { sound } = await Audio.Sound.createAsync({ uri: audioUri })
        const status = await sound.getStatusAsync()
        audioInfo = status
        await sound.unloadAsync()
      } catch (error) {
        console.warn('æ— æ³•è·å–éŸ³é¢‘ä¿¡æ¯:', error)
      }

      // åŸºäºå½•éŸ³æ—¶é•¿å’Œç”¨æˆ·äº¤äº’æ¨¡å¼ï¼Œæä¾›æ›´æ™ºèƒ½çš„è¯†åˆ«
      const duration = audioInfo?.durationMillis || 2000
      console.log(`å½•éŸ³æ—¶é•¿: ${duration}ms`)

      // æ¨¡æ‹Ÿè¯­éŸ³å¤„ç†æ—¶é—´ï¼ˆåŸºäºå®é™…å½•éŸ³æ—¶é•¿ï¼‰
      const processTime = Math.max(1000, Math.min(duration * 0.3, 3000))
      await new Promise((resolve) => setTimeout(resolve, processTime))

      // è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„è¯­éŸ³è¯†åˆ«æœåŠ¡
      // ç›®å‰ä½œä¸ºè¿‡æ¸¡æ–¹æ¡ˆï¼Œæˆ‘ä»¬æç¤ºç”¨æˆ·é…ç½®çœŸå®çš„STTæœåŠ¡
      const result = await this.promptForRealSTTService(audioUri, duration)

      return {
        success: true,
        text: result,
        provider: 'expo',
        confidence: 0.7,
        isRealRecording: true,
        duration,
      }
    } catch (error) {
      return {
        success: false,
        error: error.message,
        provider: 'expo',
      }
    }
  }

  async promptForRealSTTService(audioUri, duration) {
    // æç¤ºç”¨æˆ·é…ç½®çœŸå®çš„è¯­éŸ³è¯†åˆ«æœåŠ¡
    console.log('ğŸ™ï¸ æ£€æµ‹åˆ°çœŸå®å½•éŸ³ï¼Œæ—¶é•¿:', duration, 'ms')
    console.log('ğŸ“„ å½•éŸ³æ–‡ä»¶è·¯å¾„:', audioUri)

    // æ˜¾ç¤ºé…ç½®æŒ‡å¯¼
    console.log('ğŸ“‹ è¯­éŸ³è¯†åˆ«æœåŠ¡é…ç½®æŒ‡å¯¼:')
    console.log('1. è·å–OpenAI APIå¯†é’¥: https://platform.openai.com/account/api-keys')
    console.log('2. åœ¨.envæ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY=ä½ çš„å¯†é’¥')
    console.log('3. æˆ–åœ¨ src/config/llmConfig.js ä¸­ç›´æ¥å¡«å…¥APIå¯†é’¥')

    const configGuides = [
      `âœ¨ å½•éŸ³æˆåŠŸï¼æ—¶é•¿${Math.round(duration / 1000)}ç§’ã€‚ä¸ºäº†è¯†åˆ«è¯­éŸ³å†…å®¹ï¼Œè¯·é…ç½®OpenAI Whisper APIå¯†é’¥ã€‚é…ç½®åå³å¯äº«å—å‡†ç¡®çš„ä¸­æ–‡è¯­éŸ³è¯†åˆ«ï¼`,
      `ğŸ¤ å·²å½•åˆ¶è¯­éŸ³${Math.round(duration / 1000)}ç§’ã€‚æ·»åŠ OpenAI APIå¯†é’¥åˆ°.envæ–‡ä»¶å³å¯å¯ç”¨ä¸“ä¸šè¯­éŸ³è¯†åˆ«åŠŸèƒ½ã€‚`,
      'ğŸ“± è¯­éŸ³å·²å½•åˆ¶å®Œæˆï¼é…ç½®è¯­éŸ³è¯†åˆ«æœåŠ¡åï¼Œæˆ‘å°±èƒ½ç†è§£æ‚¨è¯´çš„å†…å®¹äº†ã€‚æ¨èä½¿ç”¨OpenAI Whisperï¼Œå‡†ç¡®ç‡å¾ˆé«˜ï¼',
    ]

    return configGuides[Math.floor(Math.random() * configGuides.length)]
  }

  // SenseVoice-smallè¯­éŸ³è¯†åˆ«
  async senseVoiceSpeechToText(audioUri) {
    try {
      console.log('ğŸ¤– ä½¿ç”¨SenseVoice-smallè¯­éŸ³è¯†åˆ«')

      // æ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡æ‹Ÿå½•éŸ³
      if (audioUri && audioUri.startsWith('mock://')) {
        console.log('ğŸ­ æ£€æµ‹åˆ°æ¨¡æ‹Ÿå½•éŸ³ï¼Œä½¿ç”¨æ¨¡æ‹ŸSTTå“åº”')
        return await this.mockSpeechToText(audioUri)
      }

      // è°ƒç”¨SenceVoiceServiceçš„WebSocketæ¥å£
      const senceVoiceService = require('./SenceVoiceService').default
      
      if (!senceVoiceService.isConnected) {
        throw new Error('SenseVoiceæœåŠ¡æœªè¿æ¥')
      }

      const result = await senceVoiceService.sendVoiceRequest(audioUri, {
        format: 'wav',
        sampleRate: 16000,
        channels: 1,
        bitDepth: 16,
      })

      // å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
      if (result.success) {
        let transcriptionText = null
        
        // å°è¯•å¤šç§å¯èƒ½çš„å“åº”æ ¼å¼
        if (result.data) {
          if (result.data.asr_result) {
            transcriptionText = result.data.asr_result
          } else if (result.data.transcription) {
            transcriptionText = result.data.transcription
          } else if (result.data.text) {
            transcriptionText = result.data.text
          } else if (typeof result.data === 'string') {
            transcriptionText = result.data
          }
        } else if (result.asr_result) {
          transcriptionText = result.asr_result
        } else if (result.transcription) {
          transcriptionText = result.transcription
        } else if (result.text) {
          transcriptionText = result.text
        }

        if (transcriptionText) {
          return {
            success: true,
            text: transcriptionText,
            provider: 'sensevoice',
            confidence: (result.data && result.data.confidence) || result.confidence || 0.9,
          }
        }
      }

      console.log('SenseVoiceå“åº”ç»“æ„:', JSON.stringify(result, null, 2))
      throw new Error('SenseVoiceè¯†åˆ«ç»“æœä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®')
    } catch (error) {
      console.log('ğŸ¯ SenseVoiceè¯­éŸ³è¯†åˆ«å¤±è´¥ï¼ˆå·²æ‹¦æˆªï¼‰:', error.message || error)
      return {
        success: false,
        error: error.message,
        provider: 'sensevoice',
      }
    }
  }

  // æ™ºèƒ½STTè·¯ç”±
  async intelligentSTT(audioUri) {
    console.log('ğŸ” STTè°ƒè¯•ä¿¡æ¯:')
    console.log('å½“å‰æä¾›å•†è®¾ç½®:', this.currentProvider)
    console.log('æœåŠ¡å¯ç”¨æ€§:', this.serviceAvailability)

    const provider = this.currentProvider === 'auto'
      ? this.selectBestProvider('stt') : this.currentProvider

    console.log(`ğŸ¤ é€‰æ‹©çš„æä¾›å•†: ${provider}`)
    console.log(`ğŸ¤ ä½¿ç”¨${provider}è¿›è¡Œè¯­éŸ³è¯†åˆ«`)

    switch (provider) {
      case 'sensevoice':
        return await this.senseVoiceSpeechToText(audioUri)
      case 'google':
        return await this.googleSpeechToText(audioUri)
      case 'openai':
        return await this.speechToText(audioUri)
      case 'azure':
        return await this.azureSpeechToText(audioUri)
      case 'expo':
        // ä¼˜å…ˆä½¿ç”¨çœŸå®çš„Expo STTï¼Œä¸å¯ç”¨æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        if (this.serviceAvailability.expoSTT) {
          return await this.expoSpeechToText(audioUri)
        }
        console.log('ğŸ”„ Expo Speech Recognitionä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬')
        return await this.simpleExpoSTT(audioUri)

      case 'web':
        return await this.webSpeechToText(audioUri)
      case 'simulation':
      default:
        console.log('ğŸ­ ä½¿ç”¨æ¨¡æ‹ŸSTTæœåŠ¡')
        return await this.mockSpeechToText(audioUri)
    }
  }

  // Google Cloudè¯­éŸ³åˆæˆ
  async googleTextToSpeech(text) {
    try {
      if (!this.googleConfig.apiKey) {
        throw new Error('Google Cloud APIå¯†é’¥æœªé…ç½®')
      }

      console.log('â˜ï¸ ä½¿ç”¨Google Cloudè¯­éŸ³åˆæˆ')

      const requestBody = {
        input: { text },
        voice: {
          languageCode: this.googleConfig.ttsLanguage,
          name: this.googleConfig.ttsVoice,
        },
        audioConfig: {
          audioEncoding: 'MP3',
        },
      }

      const response = await axios.post(
        `https://texttospeech.googleapis.com/v1/text:synthesize?key=${this.googleConfig.apiKey}`,
        requestBody,
        {
          headers: {
            'Content-Type': 'application/json',
          },
          timeout: 30000,
        },
      )

      if (response.data && response.data.audioContent) {
        return {
          success: true,
          audioData: response.data.audioContent,
          provider: 'google',
          format: 'mp3',
        }
      }

      throw new Error('Google TTSå“åº”ä¸ºç©º')
    } catch (error) {
      console.error('Googleè¯­éŸ³åˆæˆå¤±è´¥:', error)
      return {
        success: false,
        error: error.response?.data?.error?.message || error.message,
        provider: 'google',
      }
    }
  }

  // Edge TTSè¯­éŸ³åˆæˆ
  async edgeTextToSpeech(text, options = {}) {
    try {
      console.log('ğŸŒ ä½¿ç”¨Edge TTSè¯­éŸ³åˆæˆ')

      // è¯­éŸ³é…ç½®
      const voice = options.voice || 'zh-CN-XiaoyiNeural'
      const rate = options.rate || '0%'
      const pitch = options.pitch || '+0Hz'
      
      // æ„å»ºSSML
      const ssml = `
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="zh-CN">
          <voice name="${voice}">
            <prosody rate="${rate}" pitch="${pitch}">
              ${text}
            </prosody>
          </voice>
        </speak>`

      // è°ƒç”¨SenceVoiceServiceçš„WebSocketæ¥å£è¿›è¡ŒTTS
      const senceVoiceService = require('./SenceVoiceService').default
      
      if (!senceVoiceService.isConnected) {
        throw new Error('SenseVoiceæœåŠ¡æœªè¿æ¥')
      }

      // ä½¿ç”¨SenceVoiceServiceçš„sendTTSRequestæ–¹æ³•
      const result = await senceVoiceService.sendTTSRequest(text, {
        voice: voice,
        rate: rate,
        pitch: pitch,
        format: 'mp3',
      })

      if (result.success && result.data && result.data.audio_data) {
        return {
          success: true,
          audioData: result.data.audio_data,
          provider: 'edge-tts',
          format: 'mp3',
          voice: voice,
        }
      }
      
      throw new Error('Edge TTSå“åº”ä¸ºç©º')
    } catch (error) {
      console.error('Edge TTSè¯­éŸ³åˆæˆå¤±è´¥:', error)
      return {
        success: false,
        error: error.message,
        provider: 'edge-tts',
      }
    }
  }

  // æ™ºèƒ½TTSè·¯ç”±
  async intelligentTTS(text, options = {}) {
    const provider = this.currentProvider === 'auto'
      ? this.selectBestProvider('tts') : this.currentProvider

    console.log(`ğŸ”Š ä½¿ç”¨${provider}è¿›è¡Œè¯­éŸ³åˆæˆ`)

    switch (provider) {
      case 'edge-tts':
        return await this.edgeTextToSpeech(text, options)
      case 'google':
        return await this.googleTextToSpeech(text)
      case 'openai':
        return await this.textToSpeech(text, options)
      case 'azure':
        return await this.azureTextToSpeech(text)
      case 'expo':
        return await this.expoTextToSpeech(text)
      case 'web':
        return await this.webTextToSpeech(text)
      case 'simulation':
      default:
        console.log('ğŸ­ ä½¿ç”¨æ¨¡æ‹ŸTTSæœåŠ¡')
        return await this.mockTextToSpeech(text)
    }
  }

  // Google Cloudè¯­éŸ³è¯†åˆ«
  async googleSpeechToText(audioUri) {
    let audioBlob = null
    let requestBody = null

    try {
      if (!this.googleConfig.apiKey) {
        throw new Error('Google Cloud APIå¯†é’¥æœªé…ç½®')
      }

      console.log('â˜ï¸ ä½¿ç”¨Google Cloudè¯­éŸ³è¯†åˆ«')
      console.log('ğŸ”‘ APIå¯†é’¥:', `${this.googleConfig.apiKey.substring(0, 15)}...`)
      console.log('ğŸ“„ éŸ³é¢‘æ–‡ä»¶:', audioUri)

      // æ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡æ‹Ÿå½•éŸ³ï¼Œå¦‚æœæ˜¯åˆ™ä½¿ç”¨æ¨¡æ‹ŸSTT
      if (audioUri && audioUri.startsWith('mock://')) {
        console.log('ğŸ­ æ£€æµ‹åˆ°æ¨¡æ‹Ÿå½•éŸ³ï¼Œä½¿ç”¨æ¨¡æ‹ŸSTTå“åº”')
        return await this.mockSpeechToText(audioUri)
      }

      // å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºbase64å¹¶è·å–è¯¦ç»†ä¿¡æ¯
      const audioInfo = await this.convertAudioForGoogleWithInfo(audioUri)
      audioBlob = audioInfo.base64Data
      console.log('ğŸµ éŸ³é¢‘è½¬æ¢æˆåŠŸ')
      console.log('ğŸ“Š éŸ³é¢‘ä¿¡æ¯:', {
        å¤§å°: audioInfo.size,
        ç±»å‹: audioInfo.mimeType,
        æ–‡ä»¶æ‰©å±•å: audioInfo.fileExt
      })

      // æ™ºèƒ½é€‰æ‹©ç¼–ç æ ¼å¼
      const encodingOptions = this.getOptimalEncodingOptions(audioInfo)
      console.log('ğŸ”§ å°†å°è¯•ä»¥ä¸‹ç¼–ç é€‰é¡¹:', encodingOptions.map(opt => opt.encoding || 'è‡ªåŠ¨æ£€æµ‹'))

      let lastError = null
      let detailedErrors = []

      for (const [index, encodingOption] of encodingOptions.entries()) {
        const encodingName = encodingOption.encoding || 'è‡ªåŠ¨æ£€æµ‹'
        console.log(`ğŸ“¤ å°è¯•ç¼–ç é€‰é¡¹ ${index + 1}/${encodingOptions.length}: ${encodingName}`, encodingOption)

        const tryRequestBody = {
          config: {
            languageCode: this.googleConfig.sttLanguage,
            enableAutomaticPunctuation: true,
            ...encodingOption,
          },
          audio: {
            content: audioBlob,
          },
        }

        try {
          const response = await axios.post(
            `https://speech.googleapis.com/v1/speech:recognize?key=${this.googleConfig.apiKey}`,
            tryRequestBody,
            {
              headers: {
                'Content-Type': 'application/json',
              },
              timeout: 60000,
              validateStatus(status) {
                return status >= 200 && status < 600
              },
            },
          )

          console.log('ğŸ“¥ HTTPçŠ¶æ€ç :', response.status)

          if (response.status === 200) {
            if (response.data && response.data.results && response.data.results.length > 0) {
              const { transcript } = response.data.results[0].alternatives[0]
              const confidence = response.data.results[0].alternatives[0].confidence || 1.0

              console.log('âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ (ç¼–ç :', encodingName, '):', transcript)

              return {
                success: true,
                text: transcript,
                provider: 'google',
                confidence,
                language: this.googleConfig.sttLanguage,
                usedEncoding: encodingName,
              }
            } else if (response.data && response.data.results && response.data.results.length === 0) {
              console.log('âš ï¸ ç¼–ç æ­£ç¡®ä½†æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹')
              return {
                success: false,
                error: 'æœªèƒ½è¯†åˆ«åˆ°è¯­éŸ³å†…å®¹ï¼Œè¯·ç¡®ä¿å½•éŸ³æ¸…æ™°å¹¶åŒ…å«å¯è¯†åˆ«çš„è¯­éŸ³',
                provider: 'google',
              }
            } else {
              // HTTP 200ä½†æ•°æ®ç»“æ„å¼‚å¸¸
              const errorMsg = `HTTP 200 ä½†å“åº”æ•°æ®å¼‚å¸¸: ${JSON.stringify(response.data)}`
              lastError = new Error(errorMsg)
              detailedErrors.push({ encoding: encodingName, error: errorMsg })
              console.log('âŒ ç¼–ç ', encodingName, 'å¤±è´¥:', errorMsg)
            }
          } else {
            // é200çŠ¶æ€ç 
            const errorMsg = `HTTP ${response.status}: ${response.data?.error?.message || response.statusText || 'æœªçŸ¥é”™è¯¯'}`
            lastError = new Error(errorMsg)
            detailedErrors.push({ encoding: encodingName, error: errorMsg })
            console.log('âŒ ç¼–ç ', encodingName, 'å¤±è´¥:', errorMsg)
          }
        } catch (error) {
          const errorMsg = error.response?.data?.error?.message || error.message
          lastError = error
          detailedErrors.push({ encoding: encodingName, error: errorMsg })
          console.log('âŒ ç¼–ç ', encodingName, 'å¤±è´¥:', errorMsg)
          continue // å°è¯•ä¸‹ä¸€ä¸ªç¼–ç 
        }
      }

      // æ‰€æœ‰ç¼–ç éƒ½å¤±è´¥äº†ï¼Œæä¾›è¯¦ç»†é”™è¯¯ä¿¡æ¯å’Œå»ºè®®
      console.log('ğŸš¨ æ‰€æœ‰ç¼–ç é€‰é¡¹éƒ½å¤±è´¥äº†:')
      detailedErrors.forEach((err, idx) => {
        console.log(`  ${idx + 1}. ${err.encoding}: ${err.error}`)
      })
      
      // åˆ†æé”™è¯¯ç±»å‹å¹¶æä¾›å»ºè®®
      const hasAuthError = detailedErrors.some(err => 
        err.error.includes('API key') || err.error.includes('authentication') || err.error.includes('403')
      )
      const hasBadEncoding = detailedErrors.some(err => 
        err.error.includes('bad encoding') || err.error.includes('encoding')
      )
      const hasBadSampleRate = detailedErrors.some(err => 
        err.error.includes('bad sample rate') || err.error.includes('sample rate')
      )
      
      let errorSuggestion = 'æ‰€æœ‰ç¼–ç æ ¼å¼éƒ½å¤±è´¥äº†ã€‚'
      if (hasAuthError) {
        errorSuggestion += ' è¯·æ£€æŸ¥Google Cloud APIå¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚'
      } else if (hasBadEncoding && hasBadSampleRate) {
        errorSuggestion += ' éŸ³é¢‘æ–‡ä»¶å¯èƒ½å·²æŸåæˆ–æ ¼å¼ä¸å—æ”¯æŒã€‚'
      } else if (hasBadEncoding) {
        errorSuggestion += ' éŸ³é¢‘ç¼–ç æ ¼å¼å¯èƒ½ä¸å—æ”¯æŒã€‚'
      } else if (hasBadSampleRate) {
        errorSuggestion += ' éŸ³é¢‘é‡‡æ ·ç‡å¯èƒ½ä¸æ­£ç¡®ã€‚'
      }
      
      console.log('ğŸ’¡ å»ºè®®:', errorSuggestion)
      
      throw lastError || new Error(errorSuggestion)
    } catch (error) {
      // ä½¿ç”¨console.logä»¥é¿å…è§¦å‘ä»»ä½•å¯èƒ½çš„é”™è¯¯å¼¹çª—
      console.log('ğŸ¯ Googleè¯­éŸ³è¯†åˆ«å¤±è´¥ï¼ˆå·²æ‹¦æˆªï¼‰:', error.message || error)
      console.log('ğŸ¯ è¯·æ±‚è¯¦æƒ…ï¼ˆå·²æ‹¦æˆªï¼‰:', {
        url: `https://speech.googleapis.com/v1/speech:recognize?key=${this.googleConfig.apiKey?.substring(0, 10)}...`,
        config: requestBody?.config || 'æœªåˆ›å»º',
        audioDataLength: audioBlob ? audioBlob.length : 0,
        errorDetails: error.response?.data,
      })

      const errorMessage = error.response?.data?.error?.message
                          || error.response?.data?.message
                          || error.message

      return {
        success: false,
        error: errorMessage,
        provider: 'google',
        details: error.response?.data,
      }
    }
  }

  // éŸ³é¢‘æ ¼å¼è½¬æ¢ï¼ˆç”¨äºGoogleï¼‰
  async convertAudioForGoogle(audioUri) {
    try {
      console.log('ğŸµ å¼€å§‹è½¬æ¢éŸ³é¢‘æ–‡ä»¶:', audioUri)

      const response = await fetch(audioUri)
      if (!response.ok) {
        throw new Error(`è·å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: ${response.status}`)
      }

      const blob = await response.blob()
      console.log('ğŸ“ éŸ³é¢‘æ–‡ä»¶å¤§å°:', blob.size, 'bytes')
      console.log('ğŸ“ éŸ³é¢‘æ–‡ä»¶ç±»å‹:', blob.type)

      return new Promise((resolve, reject) => {
        const reader = new FileReader()
        reader.onloadend = () => {
          try {
            // ç§»é™¤data:audio/...;base64,å‰ç¼€ï¼Œåªä¿ç•™base64å†…å®¹
            const { result } = reader
            if (typeof result === 'string' && result.includes(',')) {
              const base64data = result.split(',')[1]
              console.log('âœ… Base64è½¬æ¢æˆåŠŸï¼Œé•¿åº¦:', base64data.length)
              resolve(base64data)
            } else {
              throw new Error('Base64è½¬æ¢ç»“æœæ ¼å¼å¼‚å¸¸')
            }
          } catch (err) {
            reject(new Error(`Base64è½¬æ¢å¤±è´¥: ${err.message}`))
          }
        }
        reader.onerror = () => {
          reject(new Error(`FileReaderé”™è¯¯: ${reader.error}`))
        }
        reader.readAsDataURL(blob)
      })
    } catch (error) {
      console.error('éŸ³é¢‘è½¬æ¢å¤±è´¥:', error)
      throw new Error(`éŸ³é¢‘è½¬æ¢å¤±è´¥: ${error.message}`)
    }
  }

  // å¢å¼ºç‰ˆéŸ³é¢‘è½¬æ¢ï¼ˆè·å–è¯¦ç»†ä¿¡æ¯ï¼‰
  async convertAudioForGoogleWithInfo(audioUri) {
    try {
      console.log('ğŸµ å¼€å§‹è½¬æ¢éŸ³é¢‘æ–‡ä»¶å¹¶åˆ†æä¿¡æ¯:', audioUri)
      
      const response = await fetch(audioUri)
      if (!response.ok) {
        throw new Error(`è·å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: ${response.status}`)
      }
      
      const blob = await response.blob()
      const fileExt = audioUri.split('.').pop().toLowerCase()
      
      console.log('ğŸ“ éŸ³é¢‘æ–‡ä»¶è¯¦ç»†ä¿¡æ¯:')
      console.log('  - å¤§å°:', blob.size, 'bytes')
      console.log('  - MIMEç±»å‹:', blob.type)
      console.log('  - æ–‡ä»¶æ‰©å±•å:', fileExt)
      
      return new Promise((resolve, reject) => {
        const reader = new FileReader()
        reader.onloadend = () => {
          try {
            const { result } = reader
            if (typeof result === 'string' && result.includes(',')) {
              const base64data = result.split(',')[1]
              console.log('âœ… Base64è½¬æ¢æˆåŠŸï¼Œé•¿åº¦:', base64data.length)
              
              resolve({
                base64Data: base64data,
                size: blob.size,
                mimeType: blob.type,
                fileExt: fileExt,
                originalUri: audioUri
              })
            } else {
              throw new Error('Base64è½¬æ¢ç»“æœæ ¼å¼å¼‚å¸¸')
            }
          } catch (err) {
            reject(new Error(`Base64è½¬æ¢å¤±è´¥: ${err.message}`))
          }
        }
        reader.onerror = () => {
          reject(new Error(`FileReaderé”™è¯¯: ${reader.error}`))
        }
        reader.readAsDataURL(blob)
      })
    } catch (error) {
      console.error('éŸ³é¢‘è½¬æ¢å¤±è´¥:', error)
      throw new Error(`éŸ³é¢‘è½¬æ¢å¤±è´¥: ${error.message}`)
    }
  }

  // æ™ºèƒ½é€‰æ‹©æœ€ä¼˜ç¼–ç é€‰é¡¹
  getOptimalEncodingOptions(audioInfo) {
    const { mimeType, fileExt, size } = audioInfo
    const encodingOptions = []
    
    console.log('ğŸ” æ ¹æ®éŸ³é¢‘ä¿¡æ¯æ™ºèƒ½é€‰æ‹©ç¼–ç :')
    console.log('  - MIMEç±»å‹:', mimeType)
    console.log('  - æ–‡ä»¶æ‰©å±•å:', fileExt)
    console.log('  - æ–‡ä»¶å¤§å°:', size)

    // æ ¹æ®MIMEç±»å‹å’Œæ–‡ä»¶æ‰©å±•åæ™ºèƒ½é€‰æ‹©
    if (mimeType && mimeType.includes('mp4') || fileExt === 'm4a') {
      console.log('ğŸµ æ£€æµ‹åˆ°MP4/M4Aæ ¼å¼ï¼Œä¼˜åŒ–ç¼–ç é¡ºåº')
      // M4A/MP4éŸ³é¢‘é€šå¸¸æ˜¯AACç¼–ç ï¼Œä½†Googleä¸ç›´æ¥æ”¯æŒï¼Œæ‰€ä»¥ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹
      encodingOptions.push({}) // è‡ªåŠ¨æ£€æµ‹ - æœ€ä½³é€‰æ‹©
      encodingOptions.push({ encoding: 'FLAC' })
      encodingOptions.push({ encoding: 'LINEAR16', sampleRateHertz: 44100 })
      encodingOptions.push({ encoding: 'LINEAR16', sampleRateHertz: 16000 })
    } else if (mimeType && mimeType.includes('wav') || fileExt === 'wav') {
      console.log('ğŸ¼ æ£€æµ‹åˆ°WAVæ ¼å¼ï¼Œä½¿ç”¨æœ€ä½³é…ç½®')
      encodingOptions.push({ encoding: 'LINEAR16', sampleRateHertz: 16000 })
      encodingOptions.push({ encoding: 'LINEAR16', sampleRateHertz: 44100 })
      encodingOptions.push({ encoding: 'FLAC' })
      encodingOptions.push({}) // è‡ªåŠ¨æ£€æµ‹
    } else if (mimeType && mimeType.includes('mpeg') || fileExt === 'mp3') {
      console.log('ğŸ¶ æ£€æµ‹åˆ°MP3æ ¼å¼')
      encodingOptions.push({ encoding: 'MP3', sampleRateHertz: 44100 })
      encodingOptions.push({ encoding: 'MP3', sampleRateHertz: 48000 })
      encodingOptions.push({ encoding: 'FLAC' })
      encodingOptions.push({}) // è‡ªåŠ¨æ£€æµ‹
    } else if (fileExt === '3gp') {
      console.log('ğŸ“ æ£€æµ‹åˆ°3GPæ ¼å¼')
      encodingOptions.push({ encoding: 'AMR', sampleRateHertz: 8000 })
      encodingOptions.push({ encoding: 'AMR_WB', sampleRateHertz: 16000 })
      encodingOptions.push({ encoding: 'FLAC' })
    } else if (mimeType && mimeType.includes('webm') || fileExt === 'webm') {
      console.log('ğŸŒ æ£€æµ‹åˆ°WebMæ ¼å¼')
      encodingOptions.push({ encoding: 'WEBM_OPUS', sampleRateHertz: 48000 })
      encodingOptions.push({ encoding: 'WEBM_OPUS', sampleRateHertz: 16000 })
      encodingOptions.push({ encoding: 'FLAC' })
    } else {
      console.log('â“ æœªçŸ¥æ ¼å¼ï¼Œä½¿ç”¨é€šç”¨ç¼–ç é¡ºåº')
      // é€šç”¨å¤‡é€‰æ–¹æ¡ˆï¼ŒæŒ‰å…¼å®¹æ€§æ’åº
      encodingOptions.push({}) // è‡ªåŠ¨æ£€æµ‹
      encodingOptions.push({ encoding: 'FLAC' })
      encodingOptions.push({ encoding: 'LINEAR16', sampleRateHertz: 16000 })
      encodingOptions.push({ encoding: 'MP3', sampleRateHertz: 44100 })
    }

    // æ·»åŠ æœ€åçš„å¤‡é€‰é€‰é¡¹
    encodingOptions.push({ encoding: 'LINEAR16', sampleRateHertz: 8000 })
    encodingOptions.push({ encoding: 'MULAW', sampleRateHertz: 8000 })

    console.log('ğŸ“‹ æœ€ç»ˆç¼–ç é€‰é¡¹åˆ—è¡¨:', encodingOptions.map((opt, idx) => 
      `${idx + 1}. ${opt.encoding || 'è‡ªåŠ¨æ£€æµ‹'}${opt.sampleRateHertz ? ` (${opt.sampleRateHertz}Hz)` : ''}`
    ))

    return encodingOptions
  }

  // Azureè¯­éŸ³è¯†åˆ«
  async azureSpeechToText(audioUri) {
    try {
      if (!this.azureConfig.subscriptionKey) {
        throw new Error('Azureè®¢é˜…å¯†é’¥æœªé…ç½®')
      }

      // æ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡æ‹Ÿå½•éŸ³
      if (audioUri && audioUri.startsWith('mock://')) {
        console.log('ğŸ­ æ£€æµ‹åˆ°æ¨¡æ‹Ÿå½•éŸ³ï¼Œä½¿ç”¨æ¨¡æ‹ŸSTTå“åº”')
        return await this.mockSpeechToText(audioUri)
      }

      console.log('â˜ï¸ ä½¿ç”¨Azureè¯­éŸ³è¯†åˆ«')

      // è¿™é‡Œéœ€è¦å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºAzureæ”¯æŒçš„æ ¼å¼
      const audioBlob = await this.convertAudioForAzure(audioUri)

      const response = await axios.post(
        `https://${this.azureConfig.region}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1`,
        audioBlob,
        {
          headers: {
            'Ocp-Apim-Subscription-Key': this.azureConfig.subscriptionKey,
            'Content-Type': 'audio/wav',
          },
          params: {
            language: this.azureConfig.language,
            format: 'detailed',
          },
          timeout: 30000,
        },
      )

      if (response.data && response.data.DisplayText) {
        return {
          success: true,
          text: response.data.DisplayText,
          provider: 'azure',
          confidence: response.data.Confidence || 1.0,
        }
      }

      throw new Error('Azure STTå“åº”æ ¼å¼æ— æ•ˆ')
    } catch (error) {
      // ä½¿ç”¨console.logä»¥é¿å…è§¦å‘ä»»ä½•å¯èƒ½çš„é”™è¯¯å¼¹çª—
      console.log('ğŸ¯ Azureè¯­éŸ³è¯†åˆ«å¤±è´¥ï¼ˆå·²æ‹¦æˆªï¼‰:', error.message || error)
      return {
        success: false,
        error: error.response?.data?.message || error.message,
        provider: 'azure',
      }
    }
  }

  // Azureè¯­éŸ³åˆæˆ
  async azureTextToSpeech(text) {
    try {
      if (!this.azureConfig.subscriptionKey) {
        throw new Error('Azureè®¢é˜…å¯†é’¥æœªé…ç½®')
      }

      console.log('â˜ï¸ ä½¿ç”¨Azureè¯­éŸ³åˆæˆ')

      // æ„å»ºSSML
      const ssml = `
        <speak version='1.0' xml:lang='${this.azureConfig.language}'>
          <voice xml:lang='${this.azureConfig.language}' name='${this.azureConfig.voice}'>
            ${text}
          </voice>
        </speak>`

      const response = await axios.post(
        `https://${this.azureConfig.region}.tts.speech.microsoft.com/cognitiveservices/v1`,
        ssml,
        {
          headers: {
            'Ocp-Apim-Subscription-Key': this.azureConfig.subscriptionKey,
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3',
          },
          responseType: 'blob',
          timeout: 30000,
        },
      )

      if (response.data) {
        // å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºbase64
        const reader = new FileReader()
        return new Promise((resolve, reject) => {
          reader.onloadend = () => {
            const base64data = reader.result.split(',')[1]
            resolve({
              success: true,
              audioData: base64data,
              provider: 'azure',
              format: 'mp3',
            })
          }
          reader.onerror = reject
          reader.readAsDataURL(response.data)
        })
      }

      throw new Error('Azure TTSå“åº”ä¸ºç©º')
    } catch (error) {
      console.error('Azureè¯­éŸ³åˆæˆå¤±è´¥:', error)
      return {
        success: false,
        error: error.response?.data?.message || error.message,
        provider: 'azure',
      }
    }
  }

  // Web Speech API STT (ä»…webå¹³å°)
  async webSpeechToText() {
    try {
      if (Platform.OS !== 'web' || !window.webkitSpeechRecognition) {
        throw new Error('Web Speech Recognitionä¸å¯ç”¨')
      }

      console.log('ğŸŒ ä½¿ç”¨Web Speech Recognition')

      return new Promise((resolve, reject) => {
        const recognition = new window.webkitSpeechRecognition()
        recognition.lang = 'zh-CN'
        recognition.continuous = false
        recognition.interimResults = false

        recognition.onresult = (event) => {
          const result = event.results[0][0]
          resolve({
            success: true,
            text: result.transcript,
            provider: 'web',
            confidence: result.confidence,
          })
        }

        recognition.onerror = (event) => {
          reject(new Error(`Web Speech Recognitioné”™è¯¯: ${event.error}`))
        }

        recognition.start()
      })
    } catch (error) {
      console.error('Web Speech Recognitionå¤±è´¥:', error)
      return {
        success: false,
        error: error.message,
        provider: 'web',
      }
    }
  }

  // éŸ³é¢‘æ ¼å¼è½¬æ¢ï¼ˆç”¨äºAzureï¼‰
  async convertAudioForAzure(audioUri) {
    // è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„éŸ³é¢‘å¤„ç†
    try {
      const response = await fetch(audioUri)
      return await response.blob()
    } catch (error) {
      throw new Error(`éŸ³é¢‘è½¬æ¢å¤±è´¥: ${error.message}`)
    }
  }

  // å¯ç”¨ç‰¹å®šæœåŠ¡
  enableOpenAI(apiKey) {
    this.openaiConfig.apiKey = apiKey
    this.serviceAvailability.openai = true
    this.currentProvider = 'openai'
    console.log('âœ… å·²å¯ç”¨OpenAI STT/TTSæœåŠ¡')
  }

  enableAzure(subscriptionKey, region = 'eastus') {
    this.azureConfig.subscriptionKey = subscriptionKey
    this.azureConfig.region = region
    this.serviceAvailability.azure = true
    this.currentProvider = 'azure'
    console.log('âœ… å·²å¯ç”¨Azureè¯­éŸ³æœåŠ¡')
  }

  // å¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼
  enableSimulation() {
    this.useSimulation = true
    this.currentProvider = 'simulation'
    console.log('ğŸ­ å·²å¯ç”¨æ¨¡æ‹ŸSTT/TTSæœåŠ¡')
  }

  // æ£€æµ‹å¯ç”¨æœåŠ¡
  async detectAvailableServices() {
    console.log('ğŸ” æ£€æµ‹å¯ç”¨çš„STT/TTSæœåŠ¡...')

    // é¦–å…ˆæ‰“å°å½“å‰é…ç½®
    console.log('ğŸ“‹ å½“å‰æœåŠ¡é…ç½®:')
    console.log('Googleé…ç½®:', this.googleConfig)
    console.log('OpenAIé…ç½®:', { ...this.openaiConfig, apiKey: this.openaiConfig.apiKey ? 'configured' : 'not configured' })
    console.log('Azureé…ç½®:', { ...this.azureConfig, subscriptionKey: this.azureConfig.subscriptionKey ? 'configured' : 'not configured' })

    // æ£€æµ‹Expo Speech (TTS)
    try {
      const voices = await Speech.getAvailableVoicesAsync()
      this.serviceAvailability.expo = voices && voices.length > 0
      console.log(`ğŸ“± Expo Speech TTS: ${this.serviceAvailability.expo ? 'å¯ç”¨' : 'ä¸å¯ç”¨'}`)
    } catch (error) {
      this.serviceAvailability.expo = false
      console.warn('Expo Speech TTSä¸å¯ç”¨:', error.message)
    }

    // æ£€æµ‹Expo Speech Recognition (STT)
    try {
      if (SpeechRecognition) {
        const isAvailable = await SpeechRecognition.isAvailableAsync()
        this.serviceAvailability.expoSTT = isAvailable
        console.log(`ğŸ“± Expo Speech STT: ${isAvailable ? 'å¯ç”¨' : 'ä¸å¯ç”¨'}`)
      } else {
        this.serviceAvailability.expoSTT = false
        console.log('ğŸ“± Expo Speech STT: æ¨¡å—æœªå®‰è£…')
      }
    } catch (error) {
      this.serviceAvailability.expoSTT = false
      console.warn('Expo Speech STTæ£€æµ‹å¤±è´¥:', error.message)
    }

    // æ£€æµ‹Web Speech
    if (Platform.OS === 'web') {
      this.serviceAvailability.web = !!(window.speechSynthesis && window.webkitSpeechRecognition)
      console.log(`ğŸŒ Web Speech API: ${this.serviceAvailability.web ? 'å¯ç”¨' : 'ä¸å¯ç”¨'}`)
    } else {
      this.serviceAvailability.web = false
    }

    // æ£€æµ‹OpenAI
    this.serviceAvailability.openai = !!this.openaiConfig.apiKey
    console.log(`ğŸ¤– OpenAI: ${this.serviceAvailability.openai ? 'å·²é…ç½®' : 'æœªé…ç½®'}`)

    // æ£€æµ‹Azure
    this.serviceAvailability.azure = !!this.azureConfig.subscriptionKey
    console.log(`â˜ï¸ Azure: ${this.serviceAvailability.azure ? 'å·²é…ç½®' : 'æœªé…ç½®'}`)

    // æ£€æµ‹Google Cloud
    this.serviceAvailability.google = !!(this.googleConfig.apiKey && this.googleConfig.apiKey.startsWith('AIza'))
    console.log(`â˜ï¸ Google Cloud: ${this.serviceAvailability.google ? 'å·²é…ç½®' : 'æœªé…ç½®'}`)

    console.log('ğŸ“Š æœåŠ¡å¯ç”¨æ€§æ£€æµ‹å®Œæˆ:', {
      expo: this.serviceAvailability.expo,
      expoSTT: this.serviceAvailability.expoSTT,
      web: this.serviceAvailability.web,
      openai: this.serviceAvailability.openai,
      azure: this.serviceAvailability.azure,
      google: this.serviceAvailability.google,
    })

    return this.serviceAvailability
  }

  // è·å–æœåŠ¡çŠ¶æ€
  getServiceStatus() {
    const currentProvider = this.currentProvider === 'auto'
      ? this.selectBestProvider() : this.currentProvider

    return {
      currentProvider: this.currentProvider,
      recommendedProvider: currentProvider,
      availability: this.serviceAvailability,
      config: {
        openai: {
          configured: !!this.openaiConfig.apiKey,
          model: this.openaiConfig.sttModel,
        },
        azure: {
          configured: !!this.azureConfig.subscriptionKey,
          region: this.azureConfig.region,
          language: this.azureConfig.language,
        },
        expo: {
          available: this.serviceAvailability.expo,
          platform: Platform.OS,
        },
        web: {
          available: this.serviceAvailability.web,
          platform: Platform.OS,
        },
      },
    }
  }

  // æµ‹è¯•æœåŠ¡è¿é€šæ€§
  async testService(provider) {
    console.log(`ğŸ§ª æµ‹è¯•${provider}æœåŠ¡è¿é€šæ€§...`)

    const testText = 'æµ‹è¯•'

    try {
      switch (provider) {
        case 'expo':
          const expoResult = await this.expoTextToSpeech(testText)
          return { provider, success: expoResult.success, message: expoResult.message || expoResult.error }

        case 'web':
          if (Platform.OS !== 'web') {
            return { provider, success: false, message: 'ä»…åœ¨Webå¹³å°å¯ç”¨' }
          }
          const webResult = await this.webTextToSpeech(testText)
          return { provider, success: webResult.success, message: webResult.message || webResult.error }

        case 'openai':
          if (!this.openaiConfig.apiKey) {
            return { provider, success: false, message: 'APIå¯†é’¥æœªé…ç½®' }
          }
          // è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„APIè¿é€šæ€§æµ‹è¯•
          return { provider, success: true, message: 'APIå¯†é’¥å·²é…ç½®' }

        case 'azure':
          if (!this.azureConfig.subscriptionKey) {
            return { provider, success: false, message: 'è®¢é˜…å¯†é’¥æœªé…ç½®' }
          }
          // è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„APIè¿é€šæ€§æµ‹è¯•
          return { provider, success: true, message: 'è®¢é˜…å¯†é’¥å·²é…ç½®' }

        default:
          return { provider, success: false, message: 'æœªçŸ¥çš„æœåŠ¡æä¾›å•†' }
      }
    } catch (error) {
      return { provider, success: false, message: error.message }
    }
  }

  // è·å–æœåŠ¡æ¨è
  getServiceRecommendations() {
    const recommendations = []

    // STTæœåŠ¡æ£€æŸ¥
    const sttProvider = this.selectBestProvider('stt')
    const ttsProvider = this.selectBestProvider('tts')

    if (sttProvider === 'simulation') {
      if (!this.serviceAvailability.expoSTT && !this.serviceAvailability.web
          && !this.openaiConfig.apiKey && !this.azureConfig.subscriptionKey) {
        recommendations.push({
          type: 'warning',
          message: 'STTæœåŠ¡ä¸å¯ç”¨ï¼Œè¯­éŸ³è¯†åˆ«å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ã€‚å»ºè®®å®‰è£…expo-speech-recognitionæˆ–é…ç½®äº‘ç«¯API',
        })
      }
    } else if (sttProvider === 'expo' && !this.serviceAvailability.expoSTT) {
      recommendations.push({
        type: 'info',
        message: 'Expo STTä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ã€‚å¯å®‰è£…expo-speech-recognitionè·å¾—æ›´å¥½æ•ˆæœ',
      })
    }

    // TTSæœåŠ¡æ£€æŸ¥
    if (ttsProvider === 'simulation') {
      recommendations.push({
        type: 'error',
        message: 'æ²¡æœ‰å¯ç”¨çš„TTSæœåŠ¡ï¼Œè¯­éŸ³å›å¤å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼',
      })
    } else if (ttsProvider === 'expo' && this.serviceAvailability.expo) {
      recommendations.push({
        type: 'success',
        message: 'Expo Speech TTSå¯ç”¨ï¼Œæ”¯æŒæœ¬åœ°è¯­éŸ³åˆæˆ',
      })
    }

    // äº‘æœåŠ¡æ¨è
    if (!this.openaiConfig.apiKey && !this.azureConfig.subscriptionKey) {
      recommendations.push({
        type: 'info',
        message: 'é…ç½®OpenAIæˆ–Azure APIå¯†é’¥å¯è·å¾—æ›´ä¸“ä¸šçš„è¯­éŸ³æœåŠ¡',
      })
    }

    // Webå¹³å°ç‰¹æ®Šæé†’
    if (Platform.OS === 'web' && this.serviceAvailability.web) {
      recommendations.push({
        type: 'success',
        message: 'Webå¹³å°å¯ä½¿ç”¨å…è´¹çš„æµè§ˆå™¨å†…ç½®è¯­éŸ³API',
      })
    }

    // æœ€ç»ˆæ¨è
    if (sttProvider !== 'simulation' && ttsProvider !== 'simulation') {
      recommendations.push({
        type: 'success',
        message: `æ¨èé…ç½®: STTä½¿ç”¨${sttProvider}ï¼ŒTTSä½¿ç”¨${ttsProvider}`,
      })
    }

    return recommendations
  }
}

// åˆ›å»ºå•ä¾‹å®ä¾‹
const sttTtsService = new STTTTSService()
export default sttTtsService
