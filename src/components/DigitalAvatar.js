import React, { useRef, useEffect, useState } from 'react'
import { View, StyleSheet, Dimensions, TouchableOpacity, Text } from 'react-native'
import { Video } from 'expo-av'
import digitalHumanService from '../services/DigitalHumanService'

const { width, height } = Dimensions.get('window')

export default function DigitalAvatar({ 
  style, 
  videoStyle, 
  autoPlay = true, 
  loop = true,
  showControls = false,
  enableInteraction = true,
  onMessage = null
}) {
  const videoRef = useRef(null)
  const [status, setStatus] = useState('idle') // idle, recording, processing, speaking
  const [isInitialized, setIsInitialized] = useState(false)

  useEffect(() => {
    if (autoPlay && videoRef.current) {
      videoRef.current.playAsync()
    }
  }, [autoPlay])

  useEffect(() => {
    if (enableInteraction && !isInitialized) {
      initializeDigitalHuman()
    }
  }, [enableInteraction])

  const initializeDigitalHuman = async () => {
    try {
      console.log('å¼€å§‹åˆå§‹åŒ–æ•°å­—äºº...');
      
      // å¯¼å…¥é…ç½®
      const llmConfig = await import('../config/llmConfig.js').then(m => m.default);
      console.log('LLMé…ç½®åŠ è½½å®Œæˆ');
      
      // éªŒè¯é…ç½®
      const configValidation = llmConfig.validateConfig();
      console.log('é…ç½®éªŒè¯ç»“æœ:', configValidation);
      
      if (!configValidation.isValid) {
        console.error('é…ç½®éªŒè¯å¤±è´¥:', configValidation.errors);
        alert('é…ç½®é”™è¯¯:\n' + configValidation.errors.join('\n'));
        return;
      }
      
      if (configValidation.warnings && configValidation.warnings.length > 0) {
        console.warn('é…ç½®è­¦å‘Š:', configValidation.warnings);
      }

      // é…ç½®æ•°å­—äººæœåŠ¡ï¼ˆä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„LLMï¼‰
      const config = {
        llm: {
          websocketUrl: llmConfig.responseLLM.websocketUrl,
          timeout: llmConfig.responseLLM.timeout,
          maxTokens: llmConfig.responseLLM.maxTokens,
          model: llmConfig.responseLLM.model
        },
        sttTts: {
          useSimulation: true // ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼Œä¸ä¾èµ–å¤–éƒ¨API
        }
      }

      console.log('ç¯å¢ƒé…ç½®:', llmConfig.getEnvironmentConfig())
      console.log('åˆå§‹åŒ–é…ç½®:', config)

      console.log('å¼€å§‹è°ƒç”¨digitalHumanService.initialize...')
      const initialized = await digitalHumanService.initialize(config)
      console.log('åˆå§‹åŒ–ç»“æœ:', initialized)
      
      if (initialized) {
        console.log('æ•°å­—äººæœåŠ¡åˆå§‹åŒ–æˆåŠŸ!');
        setIsInitialized(true)
        
        // è®¾ç½®å›è°ƒå‡½æ•°
        digitalHumanService.setCallbacks({
          onStatusChange: (newStatus) => {
            setStatus(newStatus)
          },
          onMessage: (message) => {
            console.log(`[${message.role}]: ${message.message}`)
            if (onMessage) {
              onMessage(message)
            }
          },
          onError: (error) => {
            console.error('æ•°å­—äººæœåŠ¡é”™è¯¯:', error)
            setStatus('idle')
          }
        })
      }
    } catch (error) {
      console.error('åˆå§‹åŒ–æ•°å­—äººå¤±è´¥:', error)
    }
  }

  const handleAvatarPress = async () => {
    if (!enableInteraction || !isInitialized) {
      return
    }

    if (status === 'idle') {
      // å¼€å§‹è¯­éŸ³å¯¹è¯
      const started = await digitalHumanService.startVoiceConversation()
      if (started) {
        console.log('å¼€å§‹è¯­éŸ³å¯¹è¯')
      }
    } else if (status === 'recording') {
      // ç»“æŸå½•éŸ³å¹¶å¤„ç†
      const processed = await digitalHumanService.stopVoiceConversation()
      if (processed) {
        console.log('è¯­éŸ³å¯¹è¯å¤„ç†å®Œæˆ')
      }
    }
  }

  const getStatusText = () => {
    switch (status) {
      case 'recording':
        return 'ğŸ¤ æ­£åœ¨å½•éŸ³...'
      case 'processing':
        return 'ğŸ¤” æ€è€ƒä¸­...'
      case 'speaking':
        return 'ğŸ—£ï¸ æ­£åœ¨è¯´è¯...'
      default:
        return enableInteraction ? 'ğŸ‘‹ ç‚¹å‡»å¼€å§‹å¯¹è¯' : ''
    }
  }

  const getStatusColor = () => {
    switch (status) {
      case 'recording':
        return '#ff4444'
      case 'processing':
        return '#ffaa00'
      case 'speaking':
        return '#00aa44'
      default:
        return '#666666'
    }
  }

  return (
    <TouchableOpacity 
      style={[styles.container, style]}
      onPress={handleAvatarPress}
      activeOpacity={enableInteraction ? 0.8 : 1}
      disabled={!enableInteraction || !isInitialized}
    >
      <View style={styles.videoContainer}>
        <Video
          ref={videoRef}
          style={[styles.video, videoStyle]}
          source={require('../../assets/images/å˜å·´é¾™å¾…æœº.mp4')}
          useNativeControls={showControls}
          resizeMode="cover"
          isLooping={loop}
          shouldPlay={autoPlay}
        />
        
        {/* çŠ¶æ€æŒ‡ç¤ºå™¨ */}
        {enableInteraction && (
          <View style={[styles.statusIndicator, { backgroundColor: getStatusColor() }]} />
        )}
      </View>
      
      {/* çŠ¶æ€æ–‡å­— */}
      {enableInteraction && (
        <Text style={styles.statusText}>{getStatusText()}</Text>
      )}
    </TouchableOpacity>
  )
}

const styles = StyleSheet.create({
  container: {
    justifyContent: 'center',
    alignItems: 'center',
  },
  videoContainer: {
    position: 'relative',
    justifyContent: 'center',
    alignItems: 'center',
    borderRadius: 20,
    overflow: 'hidden',
    backgroundColor: 'rgba(255, 255, 255, 0.05)',
    backdropFilter: 'blur(10px)',
  },
  video: {
    width: 200,
    height: 300,
    borderRadius: 20,
    backgroundColor: 'transparent',
  },
  statusIndicator: {
    position: 'absolute',
    top: 10,
    right: 10,
    width: 12,
    height: 12,
    borderRadius: 6,
    backgroundColor: '#666666'
  },
  statusText: {
    marginTop: 10,
    fontSize: 14,
    color: '#666666',
    textAlign: 'center',
  }
})